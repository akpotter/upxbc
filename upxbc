#! /usr/bin/python
# by pts@fazekas.hu at Sun Dec 31 19:21:00 CET 2017

import os
import os.path
import pipes
import struct
import subprocess
import sys
import zlib


def parse_struct(fields, data):
  values = struct.unpack('<' * (fields[0][1][0] not in '<>') + ''.join(f[1] for f in fields), data)
  return dict(zip((f[0] for f in fields), values))


def dump_struct(fields, data):
  format = '<' * (fields[0][1][0] not in '<>') + ''.join(f[1] for f in fields)
  values = struct.unpack(format, data)
  print '--- Header ' + format
  for (field_name, field_type), value in zip(fields, values):
    if isinstance(value, (int, long)):
      value = '0x%x' % value
    else:
      value = repr(value)
    print '%s = %s' % (field_name, value)
  print '---/Header'


def get_elf32_header(len_data, load_addr=0x8048000):
  # ELF 32-bit LSB  executable, Intel 80386, version 1 (GNU/Linux), statically linked, stripped.
  # Contains ELF EHDR and 1 PHDR (program header).
  if load_addr & 0xff:  # It would work even without alignment. Just for sanity.
    raise ValueError('load_addr not aligned.')
  return ''.join((  # 0x54 bytes.
      '\x7fELF\x01\x01\x01\x03\0\0\0\0\0\0\0\0\x02\0\x03\0\x01\0\0\0',
      struct.pack('<L', load_addr + 0x54),  # e_entry.
      '4\0\0\0\0\0\0\0\0\0\0\x004\0\x20\0\x01\0\x28\0\0\0\0\0\x01\0\0\0\0\0\0\0',
      # p_vaddr, p_paddr, p_filesz, p_memsz.
      struct.pack('<LLLL', load_addr, load_addr, len_data + 0x54, len_data + 0x54),
      '\x07\0\0\0\x01\0\0\0'))


def get_upx_prog():
  return (os.path.dirname(__file__) or '.') + '/tools/upx'


def run_upx_elf32(udata, tmp_filename, method, padding_char, padding_size):
  if not isinstance(udata, (str, buffer)):
    raise TypeError
  if not isinstance(method, (list, tuple)):
    raise TypeError
  # Doesn't make a difference in UpxCompressed, using a small value.
  #load_addr = 0x8048000
  # Works for compression, doesn't work for decompresson.
  #load_addr = 0x200
  # Minimum value that works for decompression. Smaller values produce:
  # ': compressed data violation'.
  load_addr = 0x101000

  elf32_size = 0x54 + len(udata) + padding_size
  elf32_header = get_elf32_header(elf32_size - 0x54, load_addr)
  assert len(elf32_header) == 0x54
  f = open(tmp_filename, 'wb')
  try:
    f.write(elf32_header)
    f.write(udata)
    if padding_size > 0:  # Avoid UPX error: ': file is too small'.
      f.write(padding_char * padding_size)
  finally:
    f.close()
  os.chmod(tmp_filename, 0700)  # Avoid UPX error: ': file not executable'

  # -qqq is totally quiet, it doesn't even print the exception.
  # -qq prints one line with the sizes.
  cmd = (
      [get_upx_prog(), '-qq'] +
      method +
      ['--', tmp_filename])
  print >>sys.stderr, 'info: running with padding_size=%d: %s' % (
      padding_size, ' ' .join(map(pipes.quote, cmd)))
  try:
    p = subprocess.Popen(cmd, stdin=subprocess.PIPE,
                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  except OSError:
    os.unlink(tmp_filename)
    raise RuntimeError('UPX not found: %x' % cmd[0])
  try:
    upx_stdout, upx_stderr = p.communicate('')
  finally:
    exit_code = p.wait()
  if exit_code:
    #assert 0, (exit_code, upx_stderr, os.stat(tmp_filename).st_size)
    os.unlink(tmp_filename)
    # 'upx: ...: IOException: file is too small -- skipped\n'
    # 'upx: ...: NotCompressibleException\n'
    # ': file is too small' in upx_stderr or  # We take care of this.
    if ': NotCompressibleException' in upx_stderr:
      return False, None
    if ': file is too large' in upx_stderr:
      return None, None
    sys.stderr.write(upx_stderr)
    raise RuntimeError('UPX failed with exit_code=0x%x.' % exit_code)
  # Don't print upx_stdout, it just contains statistics as a one-liner.
  sys.stderr.write(upx_stderr)  # !! Omit.
  return elf32_size, elf32_header


class UpxCompressed(object):
  """Data compressed by UPX."""
  # Not using collections.namedtuple because of Python 2.4 compatibility.

  # Possible values of self.format, defined in src/conf.h in UPX.
  M_NONE = 0  # Not defined by UPX.
  M_NRV2B_LE32 = 2
  M_NRV2D_LE32 = 5
  M_NRV2E_LE32 = 8
  M_LZMA = 14

  __slots__ = (
      # Compression method (algorithm) identifier, one one
      # M_NONE (0), M_NRV2B_LE32 (2), M_NRV2D_LE32 (5, rare),
      # M_NRV2E_LE32 (8, rare), M_LZMA (14).
      'method',
      # 0 means no filter, i.e. unfilter doesn't have to be applied after
      # decompress.
      #
      # Possible values for Linux i386 ELF (from
      # PackLinuxElf32x86::getFilters in src/p_lx_elf.cpp):
      # 0x00, 0x46, 0x49. Filters 0x46 and 0x49 need both filter and
      # filter_cto to be filled correctly.
      #
      # Possible values for UPX in general (from src/filteri.cpp):
      # 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a,
      # 0x0b, 0x0c, 0x0d, 0x0e, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17,
      # 0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x24, 0x25, 0x26, 0x36,
      # 0x46, 0x49, 0x50, 0x51, 0x52, 0x80, 0x81, 0x82, 0x83, 0x84, 0x85,
      # 0x86, 0x87, 0x90, 0x91, 0x92, 0x93, 0xa0, 0xa1, 0xa2, 0xa3, 0xb0,
      # 0xb1, 0xb2, 0xb3, 0xd0.
      'filter',
      # A byte (0..255) value, passed as the cto argument to unfilter.
      'filter_cto',
      # Compressed data as an str.
      'compressed_data',
      # Size of the uncompressed memory buffer, where the decompressor
      # writes its output. At least as much as the size of the uncompressed
      # input data. Additional bytes will be filled with padding_char ('\0').
      'ubufsize',
      # Position-independent i386 machine code for the decompress function.
      # Linux i386 ABI, see http://wiki.osdev.org/System_V_ABI
      # C signature: int decompress(const char *inp, unsigned ins, char *outp, unsigned *ubufsizep) __attribute__((regparm(0)));
      # Call decompress before unfilter.
      # You need to know the uncompressed size first, put it to *ubufsizep.
      # decompress will modify *ubufsizep, but eventually it will set it back to its
      # initial value.
      # M_NRV2B_LE32 (but not M_LZMA) ignores the initial value of *ubufsizep.
      # Preallocate outp to that size.
      # Pass compressed_data as inp[:ins].
      # Returns 0 on success.
      'decompress_code',
      # Position-independent i386 machine code for the unfilter (lxunfilter) function.
      # Linux i386 ABI, see http://wiki.osdev.org/System_V_ABI
      # C signature: void unfilter(char *outp, unsigned ubufsize, unsigned filter_cto) __attribute__((regparm(0)));
      # Call decompress before unfilter.
      # No need to call unfilter if filter is 0.
      # You need to know the uncompressed size first, put it to ubufsize.
      # Preallocate outp to that size.
      # Pass output of decompress as outp[:ubufsize].
      'unfilter_code',
  )

  def __init__(self, **kwargs):
    for name in self.__slots__:
      setattr(self, name, None)
    for name, value in sorted(kwargs.iteritems()):
      setattr(self, name, value)

  def __repr__(self):
    return '%s(%s)' % (
        type(self).__name__, ', '.join(
            '%s=%r' % (name, getattr(self, name))
            for name in sorted(self.__slots__)))


def upx_make_uncompressed(udata):
  """Returns UpxCompressed representing the original, uncompressed data."""
  if not isinstance(udata, (str, buffer)):
    raise TypeError
  return UpxCompressed(
      method=0,
      filter=0,
      filter_cto=0,
      compressed_data=str(udata),
      ubufsize=len(udata),
      # Based on decompress_none.nasm .
      decompress_code='\x8bD$\x10\x8b\x009D$\x08t\x04\x83\xc8\xff\xc3VW\x8bt$\x0c\x8b|$\x14\x91\xf3\xa4_^1\xc0\xc3',
      unfilter_code='\xc3',  # ret.
  )


def adler32_combine(adler1, adler2, len2):
  """Based on adler32_combine_ in zlib."""
  adler1, adler2 = adler1 & 0xffffffff, adler2 & 0xffffffff
  rem = (len2 % 65521) & 0xffffffff
  sum1 = adler1 & 0xffff
  sum2 = (rem * sum1) % 65521
  sum1 += (adler2 & 0xffff) + 65521 - 1
  sum2 += ((adler1 >> 16) & 0xffff) + ((adler2 >> 16) & 0xffff) + 65521 - rem
  if sum1 >= 65521: sum1 -= 65521
  if sum1 >= 65521: sum1 -= 65521
  if sum2 >= (65521 << 1): sum2 -= (65521 << 1)
  if sum2 >= 65521: sum2 -= 65521
  return sum1 | (sum2 << 16)


#s1 = 'foo'
#s2 = 'MYBARBAZ'
#assert adler32_combine(zlib.adler32(s1), zlib.adler32(s2), len(s2)) == (zlib.adler32(s1 + s2) & 0xffffffff)


def upx_rebuild32(ch, elf32_header, compressed_elf32_header, udata_size, udata_adler32, l_checksum, loader_code):
  bend_ofs = 170 + len(compressed_elf32_header) + len(ch.compressed_data)  # Offset of ld_pad8.
  loader_ofs = bend_ofs + (-bend_ofs & 7) + 8
  p0_filesz = loader_ofs + len(loader_code)   # or with delta -1, -2 or -3.
  p0_filesz4 = p0_filesz + (-p0_filesz & 3)  # !! Better compute.
  l_version = 13
  l_format = 12
  load_addr = 0x101000
  fields = (
      ('ei_mag', '4s', '\x7fELF'),
      ('ei_class', 'B', 1),
      ('ei_data', 'B', 1),
      ('ei_version', 'B', 1),
      ('e_osabi', 'B', 3),
      ('e_abiversion', 'B', 0),
      ('e_pad', '7s', '\0\0\0\0\0\0\0'),
      ('e_type', 'H', 2),
      ('e_machine', 'H', 3),
      ('e_version', 'L', 1),
      ('e_entry', 'L', 0xc01000 + loader_ofs),
      ('e_phoff', 'L', 0x34),
      ('e_shoff', 'L', 0),
      ('e_flags', 'L', 0),
      ('e_ehsize', 'H', 0x34),
      ('e_phentsize', 'H', 0x20),
      ('e_phnum', 'H', 2),
      ('e_shentsize', 'H', 0x28),
      ('e_shnum', 'H', 0),
      ('e_shstrndx', 'H', 0),
      ('p0_type', 'L', 1),
      ('p0_offset', 'L', 0),
      ('p0_vaddr', 'L', 0xc01000),
      ('p0_paddr', 'L', 0xc01000),
      ('p0_filesz', 'L', p0_filesz4),
      ('p0_memsz', 'L', p0_filesz4),
      ('p0_flags', 'L', 5),
      ('p0_align', 'L', 0x1000),
      ('p1_type', 'L', 1),
      ('p1_offset', 'L', load_addr),
      ('p1_vaddr', 'L', load_addr + 0x54 + udata_size),
      ('p1_paddr', 'L', load_addr + 0x54 + udata_size),
      ('p1_filesz', 'L', 0),
      ('p1_memsz', 'L', 0),
      ('p1_flags', 'L', 6),
      ('p1_align', 'L', 0x1000),
      ('l_checksum', 'L', l_checksum),
      ('l_magic', '4s', 'UPX!'),
      ('l_lsize', 'H', len(loader_code) + 12),
      ('l_version', 'B', l_version),
      ('l_format', 'B', l_format),
      ('p_progid', 'L', 0),
      ('p_filesize', 'L', 0x54 + udata_size),
      ('p_blocksize', 'L', 0x54 + udata_size),
      ('sz0_unc', 'L', 0x54),
      ('sz0_cpr', 'L', len(compressed_elf32_header)),
      ('b0_method', 'B', ch.method),
      ('b0_ftid', 'B', 0),
      ('b0_cto8', 'B', 0),
      ('b0_unused', 'B', 0),
      ('b0_cpr', '.str', compressed_elf32_header),
      ('sz1_unc', 'L', udata_size),
      ('sz1_cpr', 'L', len(ch.compressed_data)),
      ('b1_method', 'B', ch.method),
      ('b1_ftid', 'B', ch.filter),
      ('b1_cto8', 'B', ch.filter_cto),
      ('b1_unused', 'B', 0),
      ('b1_cpr', '.str', ch.compressed_data),
      ('ld_pad8', '.pad', 8),
      ('ld_ofsa', 'L', loader_ofs - 0x8c),  # Why 0x8c?
      ('ld_ofsb', 'L', loader_ofs - 4),
      ('ld_data', '.str', loader_code),
      ('ld_eof', '12s', '\0\0\0\0UPX!\0\0\0\0'),
      ('ph_magic', '4s', 'UPX!'),
      ('ph_version', 'B', l_version),
      ('ph_format', 'B', l_format),
      ('ph_method', 'B', ch.method),
      ('ph_level', 'B', 10),  # Educated guess.
      ('ph_u_adler', 'L', adler32_combine(zlib.adler32(elf32_header), udata_adler32, udata_size)),
      ('ph_c_adler', 'L', zlib.adler32(ch.compressed_data, zlib.adler32(compressed_elf32_header)) & 0xffffffff),
      ('ph_u_len', 'L', udata_size),
      ('ph_c_len', 'L', len(ch.compressed_data)),
      ('ph_u_file_size', 'L', 0x54 + udata_size),
      ('ph_filter', 'B', ch.filter),
      ('ph_filter_cto', 'B', ch.filter_cto),
      ('ph_n_mru1', 'B', 0),  # Not stored anywhere else.
      ('ph_dummy', 'B', 0xbb),
      ('overlay_ofs', 'L', 0x80),
  )

  output = []
  for name, format, value in fields:
    #print (name, format, value)
    if format == '.str':
      output.append(value)  # str.
    elif format == '.pad':
      output.append('\0' * (-sum(len(x) for x in output) % value))
    else:
      output.append(struct.pack('<' * (format[0][0] not in '<>') + format, value))
  return ''.join(output)


def upx_compress32(udata, tmp_filename, method='--ultra-brute'):
  """Compresses !! write docstring

  Tested and works with UPX 3.94.

  The corresponding decompression is not implemented.
  !! Write a Linux i386 ELF file and run it. Alternatively, distribute a
     decompressor source for Linux i386 which supports it all.

  !! doc: --no-filter, --all-filters, --all-methods

  The compressed output may be longer than the input (udata), the caller has
  to decide how to use or discard it.

  Returns:
    An UpxCompressed object describing the compressed output data.
  """
  if not isinstance(udata, (str, buffer)):
    raise TypeError
  #method = '--best --small'  # !!  --small also avoids some nops.
  #method = '--best'
  #method = '--ultra-brute --small'  # !!
  #method = '--lzma --small'   # This can force LZMA.
  #method = '-9'
  #method = '--ultra-brute --small --no-filter'  # !!
  #method = '--none'
  method = ['-' * (1 + (arg not in '123456789')) + arg for arg in
            (arg.strip('-') for arg in method.replace(',', ' ').split()) if arg]
  if not method or method == ['--none']:
    return upx_make_uncompressed(udata)

  # Example good: '--best'. Doesn't enable LZMA.
  # Example good: '--brute'. Also enables LZMA.
  # Example good: '--ultra-brute'. Also enables LZMA.
  # Example good: '--ultra-brute --lzma'.
  if not method:
    method.append('--ultra-brute')
  has_lzma = '--brute' in method or '--ultra-brute' in method or '--lzma' in method
  method[:] = [arg for arg in method if arg != '--small']
  if not has_lzma:
    # --small makes M_LZMA larger (!) by 23 bytes, so we don't apply it.
    # It also makes the M_NRV2A_LE16 a few dozen bytes smaller (avoiding NOPs etc),
    # so we apply it.
    method.append('--small')

  # !! feature: Linux i386 statically linked ELF executable compression with
  #    smaller overhead than upx.
  # !! feature: decompression. PackVmlinuxBase<T>::unpack in p_vmlinx.cpp
  #    Maybe fake a PackVmlinuxI386::getFilters has the same list of filters.
  #    We need to make sure of this: PackVmlinuxI386::has_valid_vmlinux_head()
  #    !! PackLinuxElf32::unpack seems easier but still tricky, we need to
  #       fake the ELF section headers, compressed.

  # Some golden values:
  #
  # * Input: 'X' * 0xfd1
  #   Output: .byte 201,168,170,146,88,0,96,20,84,0,0,0,0,0,0,0,144,255  (0x12 bytes)
  #   Compression: method=M_NRV2B_LE32, filter=0
  # * Input: 'X' * 0x14af
  #   Output: .byte 26,3,0,44,111,251,191,254,163,177,94,229,248,63,178,170,38,85,248,104,112,65,112,21,15,141,253,30,75,253,86,255,34,0 (0x22 bytes)
  #   Compression: method=M_LZMA filter=0
  #

  padding_char = '\0'
  # Avoid the UPX error: ': file is too small' by adding
  # padding (for Packer::checkDefaultCompressionRatio), which is OK with
  # at least 4096 bytes or 6.25% gain.
  padding_size = 4096 - len(udata) - 0x54
  if padding_size < 0:
    padding_size = 0
  elf32_size, elf32_header = run_upx_elf32(
      udata, tmp_filename, method, padding_char, padding_size)
  if elf32_size is False:  # ': NotCompressibleException'.
    # Now we try to ensure a gain of >=4096 bytes, so UPX won't report
    # ': NotCompressibleException'. To do so, we add some trailing padding which is
    # very much compressible. We don't want to add a proportional padding, because
    # ultimately we want to keep uncompressible input unchanged.
    #
    # * With M_LZMA: decompressor + literal is <3404 bytes, 4096 + 3204 == 7600 bytes
    # * With others: decompressor + literal is  <704 bytes, 4096 +  704 == 4800 bytes
    padding_size = (7600, 4800)[not has_lzma]
    elf32_size, elf32_header = run_upx_elf32(
        udata, tmp_filename, method, padding_char, padding_size)
  if not elf32_size:  # ': NotCompressibleException' or ': file is too large'.
    return upx_make_uncompressed(udata)

  # The upx binary calls upx_ucl_compress and upx_lzma_compress is called
  # with 3 different block sizes:
  #
  # * 0x54 (for the ELF32 header)
  # * 0x65e == 1630 this is the modified stub_i386_linux_elf_fold of uncompressed size sizeof(stub_i386_linux_elf_fold) - fold_hdrlen == 1758 - 128 == 1630
  #    buildLinuxLoader(
  #      stub_i386_linux_elf_entry, sizeof(stub_i386_linux_elf_entry),
  #      tmp,                       sizeof(stub_i386_linux_elf_fold),  ft );
  # * len(udata) + padding_size

  def get_ph_method(data):
    if len(data) < 36:
      raise ValueError('Shorter than PackHeader.')
    if data[-36 : -32] != 'UPX!':
      raise ValueError('Missing UPX signature in PackHeader.')
    ph_method = ord(data[-30])
    if ph_method not in (2, 5, 8, 14):
      raise ValueError('Bad ph_method: %d' % ph_method)
    return ph_method

  data = open(tmp_filename, 'rb').read()
  if has_lzma and get_ph_method(data) != 14:
    # Compress again with --small if we asked for possibly-LZMA, but we
    # ended up getting a different method. Different methods get a size
    # reduction of about 32 bytes from --small.
    method.extend(('--small', '--no-lzma'))
    elf32_size, elf32_header = run_upx_elf32(
        udata, tmp_filename, method, padding_char, padding_size)
    data = open(tmp_filename, 'rb').read()
    if get_ph_method(data) == 14:
      raise ValueError('LZMA not expected.')

  i = 0
  ehdr_fields = (
      ('ei_mag', '4s'),
      ('ei_class', 'B'),
      ('ei_data', 'B'),
      ('ei_version', 'B'),
      ('e_osabi', 'B'),
      ('e_abiversion', 'B'),
      ('e_pad', '7s'),
      ('e_type', 'H'),
      ('e_machine', 'H'),
      ('e_version', 'L'),
      ('e_entry', 'L'),
      ('e_phoff', 'L'),
      ('e_shoff', 'L'),
      ('e_flags', 'L'),
      ('e_ehsize', 'H'),
      ('e_phentsize', 'H'),
      ('e_phnum', 'H'),
      ('e_shentsize', 'H'),
      ('e_shnum', 'H'),
      ('e_shstrndx', 'H'),
  )
  ehdr = parse_struct(ehdr_fields, data[i : i + 0x34])
  dump_struct(ehdr_fields, data[i : i + 0x34])  # !! Make these calls optional.
  i += 0x34

  if ehdr['ei_mag'] != '\x7fELF':
    raise ValueError
  if ehdr['ei_class'] != 1:
    raise ValueError
  if ehdr['ei_data'] != 1:
    raise ValueError
  if ehdr['ei_version'] != 1:
    raise ValueError
  if ehdr['e_osabi'] not in (0, 3):  # 0: System V, 3: Linux.
    raise ValueError
  if ehdr['e_abiversion'] != 0:
    raise ValueError
  #if ehdr['e_pad'] != '\0\0\0\0\0\0\0':
  #  raise ValueError
  if ehdr['e_type'] != 2:
    raise ValueError('Expected an executable file.')
  if ehdr['e_machine'] != 3:  # x86.
    raise ValueError('Expected i386.')
  if ehdr['e_version'] != 1:
    raise ValueError
  if ehdr['e_ehsize'] != 0x34:
    raise ValueError
  if ehdr['e_phentsize'] != 0x20:
    raise ValueError
  if ehdr['e_flags'] != 0:
    raise ValueError
  if ehdr['e_shentsize'] not in (0, 0x28):
    raise ValueError
  if ehdr['e_shnum'] != 0:
    raise ValueError
  if ehdr['e_phnum'] != 2:
    raise ValueError(
        'Bad number of program header entries: %d' % ehdr['e_phnum'])
  if ehdr['e_phoff'] != i:
    raise ValueError

  phdr_fields = (  # ELF program header.
      ('p_type', 'L'),
      ('p_offset', 'L'),
      ('p_vaddr', 'L'),
      ('p_paddr', 'L'),
      ('p_filesz', 'L'),
      ('p_memsz', 'L'),
      ('p_flags', 'L'),
      ('p_align', 'L'),
  )
  phdr = None
  for phi in xrange(ehdr['e_phnum']):
    phdri = parse_struct(phdr_fields, data[i : i + 0x20])
    # phi=0 p_vaddr=p_paddr=0xc01000
    # phi=1 p_vaddr=p_paddr=0x1000 + load_addr
    dump_struct(phdr_fields, data[i : i + 0x20])
    i += 0x20
    if phdri['p_memsz'] != 0:
      if phdr is not None:
        raise ValueError('Too many phdrs.')
      phdr = phdri
  elf_hdr_size = i

  if phdr is None:
    raise ValueError('Missing phdr.')
  if phdr['p_type'] != 1:  # PT_LOAD.
    raise ValueError
  if phdr['p_memsz'] != phdr['p_filesz']:
    raise ValueError

  p_filesz4 = phdr['p_filesz']
  p_filesz4 += -p_filesz4 & 3  # 7 and 15 don't work here.
  if data[p_filesz4 : p_filesz4 + 16] != '\0\0\0\0UPX!\0\0\0\0UPX!':
    raise ValueError
  if phdr['p_vaddr'] != phdr['p_paddr']:
    raise ValueError
  if phdr['p_memsz'] == 0:
    raise ValueError
  if phdr['p_offset'] != 0:
    raise ValueError
  # TODO(pts): Where is the base vaddr 0x00c01000 specified in the UPX sources?
  #            Can it change if we make the load_addr smaller?

  # Based on PackLinuxElf64::unpack in p_lx_elf.cpp and p_unix.h .
  l_info_fields = (  # 12-byte trailer in header for loader
      ('l_checksum', 'L'),  # TODO(pts): Check this adler32. (It doesn't seem to match.)
      ('l_magic', '4s'),  # UPX_MAGIC_LE32 == 'UPX!'.
      ('l_lsize', 'H'),  # Decompressor size. 0x818 for ls.c32, 0x1200 for lua.c32.
      ('l_version', 'B'),  # Must be at least 10, getVersion() returns 13.
      ('l_format', 'B'),  # UPX_F_LINUX_ELF_i386 == 12.
  )
  l_info = parse_struct(l_info_fields, data[i : i + 12])
  dump_struct(l_info_fields, data[i : i + 12])
  i += 12

  if l_info['l_magic'] != 'UPX!':
    raise ValueError('Bad l_magic.')
  if l_info['l_format'] != 12:
    raise ValueError('Bad l_format.')
  if not 10 <= l_info['l_version']  <= 14:
    raise ValueError('Unsupported l_version: %d' % l_info['l_version'])

  p_info_fields = (  # 12-byte packed program header.
      ('p_progid', 'L'),
      ('p_filesize', 'L'),
      ('p_blocksize', 'L'),
  )
  p_info = parse_struct(p_info_fields, data[i : i + 12])
  dump_struct(p_info_fields, data[i : i + 12])
  i += 12

  if p_info['p_progid'] != 0:
    raise ValueError('Bad p_progid.')
  if p_info['p_filesize'] != elf32_size:
    raise ValueError
  if p_info['p_blocksize'] != elf32_size:
    raise ValueError

  data_b_info = None
  c_adler32 = 1  # zlib.adler32('').
  compressed_elf32_header = None
  for _ in xrange(ehdr['e_phnum']):  # Why 2 sections? The real data is in the 2nd one.
    # Lots of filters (b_ftid) in filteri.cpp .
    # Packer::getDecompressorSections (contains NRV and LZMA)
    # Method can be (for elf32):
    # * with --small: (!! which is the default? which one is smaller? should we specify --small? also for bmcompress.py?)
    #   * M_LZMA == 14: LZMA_ELF00,LZMA_DEC10,LZMA_DEC30.
    #   * M_NRV2B_LE32 == 2: N2BSMA10,N2BDEC10,N2BSMA20,N2BDEC20,N2BSMA30,N2BDEC30,N2BSMA40,N2BSMA50,N2BDEC50,N2BSMA60,N2BDEC60.
    #   * M_NRV2D_LE32 == 5: N2DSMA10,N2DDEC10,N2DSMA20,N2DDEC20,N2DSMA30,N2DDEC30,N2DSMA40,N2DSMA50,N2DDEC50,N2DSMA60,N2DDEC60.
    #   * M_NRV2E_LE32 == 8: N2ESMA10,N2EDEC10,N2ESMA20,N2EDEC20,N2ESMA30,N2EDEC30,N2ESMA40,N2ESMA50,N2EDEC50,N2ESMA60,N2EDEC60.
    # * without --small (fast) (!! why? 3 bytes extra output?):
    #   * M_LZMA == 14 (lua.c32): LZMA_ELF00,LZMA_DEC20,LZMA_DEC30.
    #   * M_NRV2B_LE32 == 2 (ls.c32): N2BFAS10,+80CXXXX,N2BFAS11,N2BDEC10,N2BFAS20,N2BDEC20,N2BFAS30,N2BDEC30,N2BFAS40,N2BFAS50,N2BDEC50,N2BFAS60,+40CXXXX,N2BFAS61,N2BDEC60.
    #   * M_NRV2D_LE32 == 5: N2DFAS10,+80CXXXX,N2DFAS11,N2DDEC10,N2DFAS20,N2DDEC20,N2DFAS30,N2DDEC30,N2DFAS40,N2DFAS50,N2DDEC50,N2DFAS60,+40CXXXX,N2DFAS61,N2DDEC60.
    #   * M_NRV2E_LE32 == 8: N2EFAS10,+80CXXXX,N2EFAS11,N2EDEC10,N2EFAS20,N2EDEC20,N2EFAS30,N2EDEC30,N2EFAS40,N2EFAS50,N2EDEC50,N2EFAS60,+40CXXXX,N2EFAS61,N2EDEC60.
    # PackLinuxElf32x86::addStubEntrySections (both b_method and b_ftid)
    #   LEXEC000 call main; decompress: ...
    #   LXUNF000?
    #   LXUNF002?
    #   MRUBYTE0?
    #   LXMRU005?
    #   LXMRU006?
    #   LXMRU007?
    #   LXUNF008?
    #   LXUNF010?
    #   LEXEC009?
    #   LEXEC010
    #   calls addLoader(getDecompressorSections(), NULL);
    #   LEXEC015
    #   LXUNF042?
    #   calls addFilter32(ft->id);?
    #   LXMRU058?
    #   LXUNF035?
    #   LEXEC017? (if no filter)
    #   --- This is the end of the decompression udata.
    #   IDENTSTR  '\n\0$Info: This file is packed with the UPX executable packer http://upx.sf.net $\n\0$Id: UPX ' ... '3.94 Copyright (C) 1996-2017 the UPX Team. All Rights Reserved. $\n\0'
    #   LEXEC020
    #   LUNMP000?
    #   LUNMP001?
    #   LEXEC025
    #   FOLDEXEC Patched and then compressed stub_i386_linux_elf_fold, without its first 128 bytes. The uncompressed version is typically 1630 bytes.
    b_info_fields = (  # 12-byte header before each compressed block.
        ('sz_unc', 'L'),  # Uncompressed size.
        ('sz_cpr', 'L'),  # Compressed size.
        ('b_method', 'B'),  # Compression algorithm.
        ('b_ftid', 'B'),  # Filter ID.
        ('b_cto8', 'B'),  # Filter parameter.
        ('b_unused', 'B'),
    )
    b_info = parse_struct(b_info_fields, data[i : i + 12])
    data_b_info = b_info  # The last.
    dump_struct(b_info_fields, data[i : i + 12])
    i += 12
    b_info['c_ofs'] = i  # Compressed data starts here.
    b_cpr = buffer(data, i, b_info['sz_cpr'])
    if compressed_elf32_header is None:
      compressed_elf32_header = b_cpr
    c_adler32 = zlib.adler32(b_cpr, c_adler32)
    i += b_info['sz_cpr']
  c_adler32 &= 0xffffffff
  if data_b_info['sz_unc'] != elf32_size - 0x54:
    raise ValueError
  if data_b_info['sz_unc'] != len(udata) + padding_size:
    raise ValueError
  if data_b_info['sz_cpr'] >= len(udata) + padding_size:
    raise ValueError('Compression not effective, UPX should have failed already.')
  compressed_data = buffer(data, data_b_info['c_ofs'], data_b_info['sz_cpr'])

  i += (-i & 0x7)  # Round up to 8 bytes. !! Is 4 or 16 better?
  # Loader starts here at i (with ofsa).
  ofsa, ofsb = struct.unpack('<LL', data[i : i + 8])
  i += 8
  loader_ofs = i
  sizea = i - ofsa
  print 'loader_ofs = 0x%x' % i
  # !! What are these offsets? Who emits them?
  print 'ofsa = 0x%x' % ofsa
  print 'ofsb = 0x%x' % ofsb
  print 'sizea = 0x%x' % sizea
  if i != (ehdr['e_entry'] - phdr['p_vaddr']):
    raise ValueError(
        'Bad entry point: i=0x%x ofs=0x%x' %
        (i, ehdr['e_entry'] - phdr['p_vaddr']))
  if i != ofsb + 4:
    raise ValueError('Bad ofsb.')
  if not 0 <= sizea < 0x200:  # Typically 0x8c. Why?
    raise ValueError('Bad sizea.')
  if data[i] != '\xe8':  # `call main' in the beginning of LEXEC000
    raise ValueError('Bad loader start byte.')
  if data_b_info['b_ftid'] != 0 and (data[i + 5] != '\xeb' or data[i + 6] > '\x7f'):
    # This is the jump to the real decompress routine.
    raise ValueError('Bad decompress start byte.')

  i += l_info['l_lsize'] - 12
  if data[i + 4 : i + 20] == '\0\0\0\0UPX!\0\0\0\0UPX!':
    # Sometimes it starts 4 bytes too late (e.g. in advdump.c32.tmp).
    i += 4
  if i != p_filesz4:
    raise ValueError('Bad l_lsize.')
  if data[p_filesz4 : p_filesz4 + 16] != '\0\0\0\0UPX!\0\0\0\0UPX!':
    raise ValueError('Bad signature after loader.')
  if i != len(data) - 48:
    raise ValueError('Expected PackHeader near EOF.')
  i += 12

  # SUXX: Checksum doesn't match.
  #print 'LOADER'
  ##i = 0
  #for l_size in xrange(4600, 4700):
  #  for j in xrange(-20, 200):
  #    loader_code = data[i + j : i + j + l_size]
  #    import zlib
  #    if (zlib.adler32(loader_code, 1) & 0xffffffff) == (l_info['l_checksum'] & 0xffffffff):
  #      print (l_size, j)  # !! l_checksum not found! Why??
  #print '/LOADER'

  # PackHeader::putPackHeader called from pack4().
  ph_fields = (  # PackHeader.
      ('ph_alignment', '<0s'),
      ('ph_magic', '4s'),
      ('ph_version', 'B'),
      ('ph_format', 'B'),
      ('ph_method', 'B'),
      ('ph_level', 'B'),  # Not stored anywhere else.
      ('ph_u_adler', 'L'),
      ('ph_c_adler', 'L'),
      ('ph_u_len', 'L'),
      ('ph_c_len', 'L'),
      ('ph_u_file_size', 'L'),
      ('ph_filter', 'B'),
      ('ph_filter_cto', 'B'),
      ('ph_n_mru1', 'B'),  # Not stored anywhere else.
      ('ph_dummy', 'B'),
  )
  ph = parse_struct(ph_fields, data[i : i + 32])
  dump_struct(ph_fields, data[i : i + 32])
  overlay_ofs, = struct.unpack('<L', data[i + 32 : i + 36])
  print 'overlay_ofs = 0x%x' % overlay_ofs  # dump_struct. !! Make it optional.
  i += 36
  if i != len(data):
    raise ValueError('Expected EOF on compressed ELF32 executable.')

  if overlay_ofs != elf_hdr_size + 12:
    raise ValueError
  if ph['ph_magic'] != 'UPX!':
    raise ValueError('Bad l_magic.')
  if ph['ph_version'] != l_info['l_version']:
    raise ValueError
  if ph['ph_format'] != l_info['l_format']:
    raise ValueError
  if ph['ph_method'] != data_b_info['b_method']:
    raise ValueError
  #if ph['ph_level'] != ...:  # Not stored anywhere else.
  #  raise ValueError
  u_adler32 = zlib.adler32(padding_char * padding_size, zlib.adler32(udata, zlib.adler32(elf32_header))) & 0xffffffff
  if ph['ph_u_adler'] != u_adler32:
    raise ValueError
  if ph['ph_c_adler'] != c_adler32:
    raise ValueError
  if ph['ph_u_len'] != len(udata) + padding_size:
    raise ValueError
  if ph['ph_c_len'] != len(compressed_data):
    raise ValueError
  if ph['ph_u_file_size'] != elf32_size:
    raise ValueError
  if ph['ph_filter'] != data_b_info['b_ftid']:
    raise ValueError
  if ph['ph_filter_cto'] != data_b_info['b_cto8']:
    raise ValueError
  #if ph['ph_n_mru1'] != ...:  # Not stored anywhere else.
  #  raise ValueError
  #os.unlink(tmp_filename)

  i = data.find('\n\0$Info: This file is packed with the UPX executable packer http://upx.sf.net $\n\0$Id: UPX ', loader_ofs)  # identbig.
  if i < 0:
    i = data.find(' the UPX Team. All Rights Reserved. http://upx.sf.net $\n\0', loader_ofs)  # identsmall.
    if i < 0:
      raise ValueError('UPX end-of-decompress signature not found.')
    if data[i - 23 : i - 4] != '\n$Id: UPX (C) 1996-':
      raise ValueError
  # It's important to crop at i now, because it is followed by the
  # compressed FOLDEXEC (stub_i386_linux_elf_fold), which is <1630 bytes
  # (less because of compression).
  loader_end_ofs = i
  if data_b_info['sz_cpr'] + (loader_end_ofs - loader_ofs) >= len(udata) + padding_size:
    raise ValueError('Compression not effective, UPX should have failed already.')
  if data_b_info['b_ftid'] != 0:
    decompress_ofs = loader_ofs + 7 + ord(data[loader_ofs + 6])
    decompress_code = data[decompress_ofs : loader_end_ofs]
    unfilter_code = data[loader_ofs + 7 : decompress_ofs]
    filter_cto = data_b_info['b_cto8']
  else:
    decompress_code = data[loader_ofs + 5 : loader_end_ofs]
    unfilter_code = '\xc3'  # ret.
    filter_cto = 0
  ch = UpxCompressed(
      method=data_b_info['b_method'],
      filter=data_b_info['b_ftid'],
      filter_cto=filter_cto,
      compressed_data=str(compressed_data),
      ubufsize=len(udata) + padding_size,
      decompress_code=decompress_code,
      unfilter_code=unfilter_code,
  )
  # !! Offset by 4 (chain.c32) for upx_rebuild?
  open('rebuild.in', 'wb').write(data)
  rebuilt_elf32 = upx_rebuild32(
      ch=ch,
      elf32_header=elf32_header,
      compressed_elf32_header=str(compressed_elf32_header),
      udata_size=len(udata) + padding_size,
      udata_adler32=zlib.adler32(padding_char * padding_size, zlib.adler32(udata)) & 0xffffffff,
      l_checksum=l_info['l_checksum'],
      loader_code=str(buffer(data, loader_ofs, l_info['l_lsize'] - 12)))
  open('rebuild.out', 'wb').write(rebuilt_elf32)
  open('rebuild.unc', 'wb').write(rebuilt_elf32)
  #subprocess.check_call(
  #    [get_upx_prog(), '-qq', '-d', '--', 'rebuild.unc'])
  subprocess.check_call(
      [get_upx_prog(), '-qq', '-d', '--', tmp_filename])
  os.unlink(tmp_filename)  # Keep it if there is an exception.
  return ch


FORMAT0_SMART_DECOMPRESS_CODE_SIZE = 23


def get_smart_decompress_code(ch, udata=None):
  """Returns the Linux i386 code for the smart_decompress function.

  The smart_decompress function is position-independent and self-contained, and it
  contains ch.compressed_data in the end. Its signature in the Linux i386 ABI
  (see http://wiki.osdev.org/System_V_ABI):

    void smart_decompress(char *outp) __attribute__((regparm(3)));

  It will do the decompression and write ch.ubufsize bytes starting at outp.
  The outp argument must be passed in the register eax (not on the stack).

  For uncompressed data (ch.method == 0), the overhead is only 23 bytes (==
  FORMAT0_SMART_DECOMPRESS_CODE_SIZE), i.e. the returned code is only this
  much longer than the data.

  The smart_decompress function temporarily modifies a variable in its code
  (.text), because the decompress function modifies its *ubufsizep arg (and
  then it changes it back), so you need to link your Linux program with
  `gcc -Wl,-N' for a writable .text section. Without that the program will
  fail with `Segmentation fault' on Linux.

  Args:
    ch: A UpxCompressed object.
  Returns:
    tuple of ch (possibly new) and
    str containing position-independent Linux i386 machine code for the
    smart_decompress function, including ch.ubufsize and ch.compressed_data.
  """
  format0_code = 'VW\xe8\x00\x00\x00\x00\x97^\x83\xc6\x0c\xad\x91\xf3\xa4_^\xc3'
  if ch.method == 0:  # Shortcut based on smart_decompress_none.nasm .
    # Total overhead: 23 bytes, including ubufsize_internal (4 bytes).
    code = [format0_code]
    assert len(code[0]) + 4 == FORMAT0_SMART_DECOMPRESS_CODE_SIZE
  elif ch.filter != 0:  # Based on smart_decompress_filter.nasm .
    # !! TODO(pts): Is unfilter_code = ch.unfilter_code.lstrip('\x90') safe here?
    # .rstrip('\0') isn't safe, because it ruins the relative offsets of the
    # following ch.decompress_code.
    code = [
        '\xe8\x00\x00\x00\x00\x92\x58\x6a',
        struct.pack('<B', ch.filter_cto),
        '\x05',
        struct.pack('<L', len(ch.unfilter_code) + len(ch.decompress_code) + 0x38 - 0x5),
        '\x50\x52\x68',
        struct.pack('<L', len(ch.compressed_data)),
        '\x83\xc0\x04\x50\xe8',
        struct.pack('<L', len(ch.unfilter_code) + 0x38 - 0x1e),
        '\x85\xc0\x74\x02\xfa\xf4\x58\x58\x58\x5a\xff\x32\x50\xe8\x08\x00\x00\x00\x58\x58\x58\xc3',
        'UPX~', ch.unfilter_code, ch.decompress_code,
    ]
  else:  # Based on smart_decompress.nasm .
    code = [
        '\xe8\x00\x00\x00\x00\x92\x58\x05',
        struct.pack('<L', len(ch.decompress_code) + 0x2b - 0x5),
        '\x50\x52\x68',
        struct.pack('<L', len(ch.compressed_data)),
        '\x83\xc0\x04\x50\xe8\x0f\x00\x00\x00\x85\xc0\x74\x02\xfa\xf4\x58\x58\x58\x58\xc3',
        'UPX~', ch.decompress_code,
    ]
  code.extend((struct.pack('<L', ch.ubufsize), ch.compressed_data))
  code = ''.join(code)
  # If too long, use the uncompressed version.
  if (udata is not None and
      len(code) >= FORMAT0_SMART_DECOMPRESS_CODE_SIZE + len(udata)):
    ch = upx_make_uncompressed(udata)
    code = ''.join((format0_code, struct.pack('<L', len(udata)), udata[:]))
  return ch, code


def bmcompress32_asm(udata, tmp_filename, method='--ultra-brute', prefix_size=0):
  """Compresses !! write docstring"""
  if not isinstance(udata, (str, buffer)):
    raise TypeError
  if len(udata) < prefix_size:
    raise ValueError('Uncompressed data too short.')
  udata_after_prefix = buffer(udata, prefix_size)
  ch = upx_compress32(udata_after_prefix, tmp_filename, method)
  ch, smart_decompress_code = get_smart_decompress_code(ch, udata_after_prefix)

  def to_byte(s):
    return '.byte %s\n' % ','.join(str(ord(c)) for c in s)

  output = [
      '/* smart_decompress_size = %d */\n' % len(smart_decompress_code),
      '.text\n',
      '.globl prefix_data\n',
      'prefix_data:\n',
      to_byte(buffer(udata, 0, prefix_size)),
      '.globl prefix_data_end\n',
      'prefix_data_end:\n',
      '.globl uncompressed_data_size\n',
      'uncompressed_data_size:  /* must be directly in front of compressed_data */\n'
      '.long %d\n' % len(udata_after_prefix),
      '.globl ubufsize\n'
      # Can be larger than len(udata) by padding_size.
      'ubufsize:  /* must be directly in front of uncompressed_data_size */\n',
      '.long %d\n' % ch.ubufsize,
      '.globl smart_decompress\n',
      'smart_decompress:\n',
      to_byte(smart_decompress_code),
  ]

  open('deco.s', 'w').write(''.join(output))
  open('deco.h', 'w').write(''.join((
      'void smart_decompress(char *outp) __attribute__((regparm(3)));\n'
      'extern unsigned ubufsize;\n'
      'extern const unsigned uncompressed_data_size;\n'
      'extern const char prefix_data[];\n'
      'extern const char prefix_data_end[];\n')))

  if ch.ubufsize < 0x23:
    raise ValueError  # !! Doesn't work for too short output, move in wrong direction.
  output = [
      udata[:prefix_size],
      '\xe8\x00\x00\x00\x00',
      '\x5b',
      struct.pack('<1sL', '\xb9', len(smart_decompress_code)),
      '\x8d\x74\x0b\x1d',
      struct.pack('<2sL', '\x8d\xbe', ch.ubufsize - 0x23),
      '\x41',
      '\xfd',
      '\xf3\xa4',
      '\xfc',
      '\x8d\x43\xfb',
      '\x50',
      struct.pack('<1sL', '\xe9', ch.ubufsize - 0x23),
      smart_decompress_code,
  ]
  open('compr.c32', 'wb').write(''.join(output))

  # !! Get new stats, with details on len(decompress_code) etc.
  # method=M_LZMA filter=0 decompress_size=2835
  # --small method=M_LZMA filter=0 decompress_size=2858
  # method=M_LZMA filter=0x49 decompress_size=2923
  # --small method=M_LZMA filter=0x49 decompress_size=2946  (strange, --small is larger)
  # method=M_NRV2B_LE32 filter=0x49 decompress_size=328
  # --small method=M_NRV2B_LE32 filter=0x49 decompress_size=297

  # !! Handle if compressed data is not smaller than the original (in .c32).


def main(argv):
  prefix_size = 7  # !!
  prefix_size = 5  # !! .c32 signature.
  for filename in argv[1:]:
    print >>sys.stderr, 'info: compressing: %s' % filename
    code = open(filename, 'rb').read()
    tmp_filename = filename + '.tmp'
    code = bmcompress32_asm(code, tmp_filename, prefix_size=prefix_size)
  #open(tmp_filename, 'wb').write(code)


if __name__ == '__main__':
  sys.exit(main(sys.argv))
